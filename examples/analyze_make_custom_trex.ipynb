{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = load_dataset('relbert/t_rex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['relation', 'head', 'tail', 'title', 'text'],\n",
       "    num_rows: 1274264\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = set(dataset_orig[\"train\"][\"relation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = list(all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trex_relations2questions2_cleaned.json') as f:\n",
    "    relations2questions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_good_relations = []\n",
    "\n",
    "for relation in all_relations:\n",
    "    if relation in relations2questions.keys():\n",
    "        all_good_relations.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_per_relation(dataset_relations_array, relation):\n",
    "    return np.where(dataset_relations_array == relation)[0]\n",
    "\n",
    "dataset_relations_array = np.array(dataset_orig[\"train\"][\"relation\"])\n",
    "\n",
    "relations_to_points_dict = {}\n",
    "for relation in all_good_relations:\n",
    "    relations_to_points_dict[relation] = get_points_per_relation(dataset_relations_array, relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for relation in relations_to_points_dict.keys():\n",
    "    relations_to_points_dict[relation] = np.array(relations_to_points_dict[relation]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save relations_to_points_dict\n",
    "with open('trex_relations2idxs.json', 'w') as fp:\n",
    "    json.dump(relations_to_points_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relations = []\n",
    "train_points = []\n",
    "ood_relations = []\n",
    "ood_points = []\n",
    "\n",
    "for relations in all_good_relations:\n",
    "    if np.random.rand() < 0.7:\n",
    "        train_relations.append(relations)\n",
    "        train_points.append(relations_to_points_dict[relations])\n",
    "    else:\n",
    "        ood_relations.append(relations)\n",
    "        ood_points.append(relations_to_points_dict[relations])\n",
    "\n",
    "train_points = np.concatenate(train_points)\n",
    "ood_points = np.concatenate(ood_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"custom_trex/train_test_relations.npy\", train_relations)\n",
    "np.save(\"custom_trex/ood_relations.npy\", ood_relations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"custom_trex/ood_points.npy\", ood_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_points = []\n",
    "train_test_points = []\n",
    "\n",
    "for point in train_points:\n",
    "    if np.random.rand() < 0.7:\n",
    "        train_train_points.append(point)\n",
    "    else:\n",
    "        train_test_points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"custom_trex/train_points.npy\", train_train_points)\n",
    "np.save(\"custom_trex/test_points.npy\", train_test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_train_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"custom_trex/train_points.npy\", train_train_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_points = np.random.choice(train_test_points, 5000, replace=False)\n",
    "\n",
    "np.save(\"custom_trex/test_points_small.npy\", small_test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ood_points = np.random.choice(ood_points, 5000, replace=False)\n",
    "\n",
    "np.save(\"custom_trex/ood_points_small.npy\", small_ood_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
