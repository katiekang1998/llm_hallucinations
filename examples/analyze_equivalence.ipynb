{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def call_instructgpt_with_answers(questions, model_predictions, ground_truths):\n",
    "    # if exact_match_score(model_prediction, ground_truth):\n",
    "    #     return 1\n",
    "    api_key = open(\"/data/katie_kang/openai_key_file.txt\", \"r\").read()\n",
    "    openai.api_key = api_key.strip()\n",
    "\n",
    "    prompt_template1 = \"\"\"Are the answers equivalent?\n",
    "\n",
    "Ex 1:\n",
    "Q: Who was leader of Revolutionary Army?\n",
    "A1: George Washington\n",
    "A2: US President Washington\n",
    "\n",
    "Ex 2:\n",
    "Q: Who is the best RL Researcher?\n",
    "A1: Professor Sergey Levine\n",
    "A2: Professor Pieter Abbeel\n",
    "\n",
    "Ex 3:\n",
    "Q: country of citizenship of McKean?\n",
    "A1: United States\n",
    "A2: American\n",
    "\n",
    "Ex 4:\n",
    "Q: What genre is Taxi for Two?\n",
    "A1: romantic comedy film\n",
    "A2: comedy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    prompt_template2 = None\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        if i == 0:\n",
    "            prompt_template2 = \"\"\"Ex {}:\n",
    "Q: {}\n",
    "A1: {}\n",
    "A2: {}\n",
    "\n",
    "\"\"\".format(i+5, questions[i], model_predictions[i], ground_truths[i])\n",
    "        else:\n",
    "            prompt_template2 += \"\"\"Ex {}:\n",
    "Q: {}\n",
    "A1: {}\n",
    "A2: {}\n",
    "\n",
    "\"\"\".format(i+5, questions[i], model_predictions[i], ground_truths[i])\n",
    "\n",
    "    prompt_template3 = \"\"\"Ex 1 Equivalent? Yes\n",
    "Ex 2 Equivalent? No\n",
    "Ex 3 Equivalent? Yes\n",
    "Ex 4 Equivalent? Yes\n",
    "\"\"\"\n",
    "\n",
    "    prompt = prompt_template1 + prompt_template2 + prompt_template3\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",  # or another model version\n",
    "        # prompt=[filled_prompt, filled_prompt],\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    print(prompt)\n",
    "    model_response = response.choices[0].text.strip()\n",
    "    print(model_response)\n",
    "    1/0\n",
    "    exit()\n",
    "\n",
    "\n",
    "    # Interpret the model's response\n",
    "    if model_response == \"Yes\":\n",
    "        return 1\n",
    "    elif model_response == \"No\":\n",
    "        return 0\n",
    "    else:\n",
    "        print('WARNING', model_response)\n",
    "        return 0\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the answers equivalent?\n",
      "\n",
      "Ex 1:\n",
      "Q: Who was leader of Revolutionary Army?\n",
      "A1: George Washington\n",
      "A2: US President Washington\n",
      "\n",
      "Ex 2:\n",
      "Q: Who is the best RL Researcher?\n",
      "A1: Professor Sergey Levine\n",
      "A2: Professor Pieter Abbeel\n",
      "\n",
      "Ex 3:\n",
      "Q: country of citizenship of McKean?\n",
      "A1: United States\n",
      "A2: American\n",
      "\n",
      "Ex 4:\n",
      "Q: What genre is Taxi for Two?\n",
      "A1: romantic comedy film\n",
      "A2: comedy\n",
      "\n",
      "Ex 5:\n",
      "Q: Who approved the Apple Public Source License?\n",
      "A1: OSI\n",
      "A2: Apple\n",
      "\n",
      "Ex 6:\n",
      "Q: Who approved the GPL?\n",
      "A1: OSI\n",
      "A2: Linus Torvalds\n",
      "\n",
      "Ex 7:\n",
      "Q: Who approved the zlib license?\n",
      "A1: FSF\n",
      "A2: GNU Project\n",
      "\n",
      "Ex 8:\n",
      "Q: Who approved the MIT?\n",
      "A1: Free Software Foundation\n",
      "A2: MIT\n",
      "\n",
      "Ex 1 Equivalent? Yes\n",
      "Ex 2 Equivalent? No\n",
      "Ex 3 Equivalent? Yes\n",
      "Ex 4 Equivalent? Yes\n",
      "\n",
      "Ex 5 Equivalent? No\n",
      "Ex 6 Equivalent? No\n",
      "Ex 7 Equivalent? No\n",
      "Ex 8 Equivalent? No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/katie_kang/trlx/examples/analyze_equivalence.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     predictions\u001b[39m.\u001b[39mappend(prediction)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     questions\u001b[39m.\u001b[39mappend(question)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(call_instructgpt_with_answers(questions, answers, predictions))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(question, answer, prediction)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[1;32m/data/katie_kang/trlx/examples/analyze_equivalence.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m model_response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(model_response)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m exit()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# Interpret the model's response\u001b[39;00m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('ckpts/sft_ctrex_llama7B_2_commit_lr1e-5_2/checkpoint_30000/hf_model/ood_output_strings.npy')\n",
    "\n",
    "equivalent_all = []\n",
    "\n",
    "num_points_per_prompt = 4\n",
    "for i in tqdm(range(len(data)//num_points_per_prompt)):\n",
    "\n",
    "\n",
    "    # line = data[i]\n",
    "    # # try:\n",
    "    # answer = line.split('Label: ')[1].strip()\n",
    "    # prediction = line.split('The answer is')[1].split('Label:')[0].strip()[0:-1]\n",
    "    # question = line.split('<unk>')[-1].split('?')[0].strip() + '?'\n",
    "\n",
    "    answers = []\n",
    "    predictions = []\n",
    "    questions = []\n",
    "\n",
    "    for j in range(i, min(i+num_points_per_prompt, len(data))):\n",
    "        line = data[j]\n",
    "        answer = line.split('Label: ')[1].strip()\n",
    "        prediction = line.split('The answer is')[1].split('Label:')[0].strip()[0:-1]\n",
    "        question = line.split('<unk>')[-1].split('?')[0].strip() + '?'\n",
    "\n",
    "        answers.append(answer)\n",
    "        predictions.append(prediction)\n",
    "        questions.append(question)\n",
    "\n",
    "\n",
    "    result = int(call_instructgpt_with_answers(questions, answers, predictions))\n",
    "    print(question, answer, prediction)\n",
    "    print(result)\n",
    "    # except:\n",
    "    #     print('WARNING', line)\n",
    "    #     result = 0\n",
    "    equivalent_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'equivalent_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/katie_kang/trlx/examples/analyze_equivalence.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcompute.safe.ai/data/katie_kang/trlx/examples/analyze_equivalence.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m equivalent_all\n",
      "\u001b[0;31mNameError\u001b[0m: name 'equivalent_all' is not defined"
     ]
    }
   ],
   "source": [
    "equivalent_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # prompt_template = \"\"\"\n",
    "    # Are the answers equivalent? Answer \"Yes\" or \"No\"\n",
    "\n",
    "    # Ex 1:\n",
    "    # Q: Who was leader of Revolutionary Army?\n",
    "    # A1: George Washington\n",
    "    # A2: US President Washington\n",
    "    # Equivalent? Yes\n",
    "\n",
    "    # Ex 2:\n",
    "    # Q: Who is the best RL Researcher?\n",
    "    # A1: Professor Sergey Levine\n",
    "    # A2: Professor Pieter Abbeel\n",
    "    # Equivalent? No\n",
    "\n",
    "    # Ex 3:\n",
    "    # Q: country of citizenship of McKean?\n",
    "    # A1: United States\n",
    "    # A2: American\n",
    "    # Equivalent? Yes\n",
    "\n",
    "    # Ex 4:\n",
    "    # Q: What genre is Taxi for Two?\n",
    "    # A1: romantic comedy film\n",
    "    # A2: comedy\n",
    "    # Equivalent? Yes\n",
    "\n",
    "    # Ex 5:\n",
    "    # Q: {}\n",
    "    # A1: {}\n",
    "    # A2: {}\n",
    "    # Equivalent?\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
